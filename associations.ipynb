{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlxtend\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('retail_dataset.csv', sep=',') \n",
    "## Print top 5 rows \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = (df['0'].unique())\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of the __apriori__ module given by `mlxtend` library, we need to convert the dataset according to it’s liking. The __apriori__ module requires a dataframe that has either 0 and 1 or True and False as data (This is called One Hot Encoding - [read here](https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/). The data we have is all string (name of items), we need to One Hot Encode the data.\n",
    "\n",
    "### Custom One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vals = []\n",
    "#def custom():\n",
    "for index, row in df.iterrows():\n",
    "    labels = {}\n",
    "    uncommons = list(set(items) - set(row))\n",
    "    commons = list(set(items).intersection(row))\n",
    "    for uc in uncommons:\n",
    "        labels[uc] = 0\n",
    "    for com in commons:\n",
    "        labels[com] = 1\n",
    "    encoded_vals.append(labels)\n",
    "encoded_vals[0]\n",
    "ohe_df = pd.DataFrame(encoded_vals)\n",
    "ohe_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation of apriori module\n",
    "`apriori(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0, low_memory=False)`\n",
    "\n",
    "* `df` : One-Hot-Encoded DataFrame or DataFrame that has 0 and 1 or True and False as values\n",
    "* `min_support` : Floating point value between 0 and 1 that indicates the minimum support required for an itemset to be selected. (number of observation with item / total observations)\n",
    "* `use_colnames` : This allows to preserve column names for itemset making it more readable.\n",
    "* `max_len` : Max length of itemset generated. If not set, all possible lengths are evaluated.\n",
    "* `verbose` : Shows the number of iterations if >= 1 and low_memory is True. If =1 and low_memory is False , shows the number of combinations.\n",
    "* `low_memory` : If True, uses an iterator to search for combinations above min_support. Note that while low_memory=True should only be used for large dataset if memory resources are limited, because this implementation is approx. 3–6x slower than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items = apriori(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
    "freq_items.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results\n",
    "### Support vs Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rules['support'], rules['confidence'], alpha=0.5)\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('confidence')\n",
    "plt.title('Support vs Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vs Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rules['support'], rules['lift'], alpha=0.5)\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('lift')\n",
    "plt.title('Support vs Lift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift vs Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.polyfit(rules['lift'], rules['confidence'], 1)\n",
    "fit_fn = np.poly1d(fit)\n",
    "plt.plot(rules['lift'], rules['confidence'], 'yo', rules['lift'], \n",
    " fit_fn(rules['lift']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real groceries dataset\n",
    "The dataset is the result of preprocessing of a real dataset on grocery transactions from the arules R library. It contains actual transactions at a grocery outlet over 30 days. The dataset can be found [here](https://drive.google.com/file/d/1SAM7xAO5ZTuw5CNWmU1C5S3Oikq0rjdO/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data_sets/groceries_matrix.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file, sep=',') \n",
    "## Print top 5 rows \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items = apriori(df, min_support=0.05, use_colnames=True, verbose=1)\n",
    "print(len(freq_items))\n",
    "print(freq_items.head(10))\n",
    "freq_items.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.02)\n",
    "print(len(rules))\n",
    "rules.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network graph below shows associations between selected items. Larger circles imply higher support, while red circles imply higher lift:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"images/association-rules-network-graph2.png\" title=\"Associations between selected items. Visualized using the arulesViz R library.\">\n",
    "    <figcaption>Fig.1 - Associations between selected items. Visualized using the arulesViz R library.</figcaption>\n",
    "</figure>\n",
    "\n",
    "The figure is from this  [post](https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View this [post](https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html)\n",
    "\n",
    "https://rpubs.com/aru0511/GroceriesDatasetAssociationAnalysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
